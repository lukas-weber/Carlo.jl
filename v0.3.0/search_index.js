var documenterSearchIndex = {"docs":
[{"location":"evaluables.html#evaluables","page":"Evaluables","title":"Evaluables","text":"In addition to simply calculating the averages of some observables in your Monte Carlo simulations, sometimes you are also interested in quantities that are functions of these observables, such as the Binder cumulant which is related to the ratio of moments of the magnetization.\n\nThis presents two problems. First, estimating the errors of such quantities is not trivial due to correlations. Second, simply computing functions of quantities with errorbars incurs a bias.\n\nLuckily, Carlo can help you with this by letting you define such quantities – we call them evaluables – in the Carlo.register_evaluables(YourMC, eval, params) function.\n\nThis function gets an AbstractEvaluator which can be used to","category":"section"},{"location":"evaluables.html#Example","page":"Evaluables","title":"Example","text":"This is an example for a register_evaluables implementation for a model of a magnet.\n\nusing Carlo\nstruct YourMC <: AbstractMC end # hide\n\nfunction Carlo.register_evaluables(\n    ::Type{YourMC},\n    eval::AbstractEvaluator,\n    params::AbstractDict,\n)\n\n    T = params[:T]\n    Lx = params[:Lx]\n    Ly = get(params, :Ly, Lx)\n    \n    evaluate!(eval, :Susceptibility, (:Magnetization2,)) do mag2\n        return Lx * Ly * mag2 / T\n    end\n\n    evaluate!(eval, :BinderRatio, (:Magnetization2, :Magnetization4)) do mag2, mag4\n        return mag2 * mag2 / mag4\n    end\n\n    return nothing\nend\n\nNote that this code is called after the simulation is over, so there is no way to access the simulation state. However, it is possible to get the needed information about the system (e.g. temperature, system size) from the task parameters params.","category":"section"},{"location":"evaluables.html#Carlo.evaluate!","page":"Evaluables","title":"Carlo.evaluate!","text":"evaluate!(func::Function, eval::AbstractEvaluator, name::Symbol, (ingredients::Symbol...))\n\nDefine an evaluable called name, i.e. a quantity depending on the observable averages ingredients.... The function func will get the ingredients as parameters and should return the value of the evaluable. Carlo will then perform jackknifing to calculate a bias-corrected result with correct error bars that appears together with the observables in the result file.\n\n\n\n\n\n","category":"function"},{"location":"parallel_run_mode.html#parallel_run_mode","page":"Parallel run mode","title":"Parallel run mode","text":"One of Carlo’s features is to automatically parallelize independent Monte Carlo simulation runs over MPI. These runs can either share the same set of parameters – in which case their results are averaged – or have different parameters entirely.\n\nSometimes this kind of trivial parallelism is not satisfactory. For example, it does not shorten the time needed for thermalization, and some Monte Carlo algorithms can benefit from some sort of population control that exchanges data between different simulations of the same random process.\n\nFor these cases, Carlo features a parallel run mode where each Carlo run does not run on one but multiple MPI ranks. Parallel run mode is enabled in JobInfo by passing the ranks_per_run argument. \n\nAn example for how parallel run mode is used can be found in the implementation of ParallelTemperingMC.","category":"section"},{"location":"parallel_run_mode.html#Parallel-AbstractMC-interface","page":"Parallel run mode","title":"Parallel AbstractMC interface","text":"In order to use parallel run mode, the Monte Carlo algorithm must implement a modified version of the AbstractMC interface including additional MPI.Comm arguments that allow coordination between the different ranks per run.\n\nThe first three functions\n\nCarlo.init!(mc::YourMC, ctx::MCContext, params::AbstractDict, comm::MPI.Comm)\nCarlo.sweep!(mc::YourMC, ctx::MCContext, comm::MPI.Comm)\nCarlo.measure!(mc::YourMC, ctx::MCContext, comm::MPI.Comm)\n\nsimply receive an additional comm argument. An important restriction here is that only rank 0 can make measurements on the given MCContext, so you are responsible to communicate the measurement results to that rank.\n\nFor checkpointing, there is a similar catch.\n\nCarlo.write_checkpoint(mc::YourMC, out::Union{HDF5.Group,Nothing}, comm::MPI.Comm)\nCarlo.read_checkpoint!(mc::YourMC, in::Union{HDF5.Group,Nothing}, comm::MPI.Comm)\n\nIn these methods, only rank 0 receives an HDF5.Group and the other ranks need to communicate. Carlo does not use the collective writing mode of parallel HDF5.\n\nSometimes, you also want to share work during the construction of YourMC. For this reason, Carlo will add the hidden parameter _comm to the parameter dictionary received by the constructor YourMC(params::AbstractDict). params[:_comm] is then an MPI communicator similar to the comm argument of the functions above.\n\nLastly, the Carlo.register_evaluables function remains the same as in the normal interface.","category":"section"},{"location":"jobtools.html#jobtools","page":"JobTools","title":"JobTools","text":"This submodule contains tools to specify or read job information necessary to run Carlo calculations.","category":"section"},{"location":"jobtools.html#TaskMaker","page":"JobTools","title":"TaskMaker","text":"","category":"section"},{"location":"jobtools.html#Carlo.JobTools.JobInfo","page":"JobTools","title":"Carlo.JobTools.JobInfo","text":"JobInfo(\n    job_directory_prefix::AbstractString,\n    mc::Type;\n    checkpoint_time::Union{AbstractString, Dates.Period},\n    run_time::Union{AbstractString, Dates.Period},\n    tasks::Vector{TaskInfo},\n    rng::Type = Random.Xoshiro,\n    ranks_per_run::Union{Integer, Symbol} = 1,\n)\n\nHolds all information required for a Monte Carlo calculation. The data of the calculation (parameters, results, and checkpoints) will be saved under job_directory_prefix.\n\nmc is the the type of the algorithm to use, implementing the abstract_mc interface.\n\ncheckpoint_time and run_time specify the interval between checkpoints and the total desired run_time of the simulation. Both may be specified as a string of format [[hours:]minutes:]seconds\n\nEach job contains a set of tasks, corresponding to different sets of simulation parameters that should be run in parallel. The TaskMaker type can be used to conveniently generate them.\n\nrng sets the type of random number generator that should be used.\n\nSetting the optional parameter ranks_per_run > 1 enables Parallel run mode. The special value ranks_per_run = :all uses all available ranks for a single run.\n\n\n\n\n\n","category":"type"},{"location":"jobtools.html#Carlo.JobTools.TaskInfo","page":"JobTools","title":"Carlo.JobTools.TaskInfo","text":"TaskInfo(name::AbstractString, params::Dict{Symbol,Any})\n\nHolds information of one parameter set in a Monte Carlo calculation. While it is possible to construct it by hand, for multiple tasks, it is recommended to use TaskMaker for convenience.\n\nSpecial parameters\n\nWhile params can hold any kind of parameter, some are special and used to configure the behavior of Carlo.\n\nsweeps: required. The minimum number of Monte Carlo measurement sweeps to perform for the task.\nthermalization: required. The number of thermalization sweeps to perform.\nbinsize: required. The internal default binsize for observables. Carlo will merge this many samples into one bin before saving them.   On top of this, a rebinning analysis is performed, so that this setting mostly affects disk space and IO efficiency. To get correct autocorrelation times, it should be 1. In all other cases much higher.\nrng: optional. Type of the random number generator to use. See rng.\nseed: optional. Optionally run calculations with a fixed seed. Useful for debugging.\nrebin_length: optional. Override the automatic rebinning length chosen by Carlo (⚠ do not set without knowing what you are doing).\nrebin_sample_skip: optional. Skip the first N internal bins of each run when performing the rebinning analysis. Useful if thermalization was not set high enough at the start of the simulation.\nestimate_covariance: optional. Estimate the covariance matrix of all array-valued observables and evaluables.\nmax_runs_per_task: optional. If set, puts a limit on the maximum number of runs that will be scheduled for this task.\n\nOut of these parameters, it is only permitted to change sweeps for an existing calculation. This is handy to run the simulation for longer or shorter than planned originally.\n\n\n\n\n\n","category":"type"},{"location":"jobtools.html#Carlo.JobTools.result_filename","page":"JobTools","title":"Carlo.JobTools.result_filename","text":"result_filename(job::JobInfo)\n\nReturns the filename of the .results.json file containing the merged results of the calculation of job.\n\n\n\n\n\n","category":"function"},{"location":"jobtools.html#Carlo.JobTools.run_time_from_slurm","page":"JobTools","title":"Carlo.JobTools.run_time_from_slurm","text":"run_time_from_slurm(;grace_factor=0.95, default=Hour(24))\n\nWhen running inside a Slurm job, returns the remaining wall-clock time based on the environment variable SLURM_JOB_END_TIME. The result is multiplied by grace_factor to allow for a small period for wrapping up the calculation and saving the final results.\n\nThe result of this function can be used for the run_time parameter of the JobInfo struct.\n\nIf SLURM_JOB_END_TIME is not set, default is returned.\n\n\n\n\n\n","category":"function"},{"location":"jobtools.html#Carlo.start-Tuple{JobInfo, AbstractVector{<:AbstractString}}","page":"JobTools","title":"Carlo.start","text":"start(job::JobInfo, ARGS)\n\nCall this from your job script to start the Carlo command line interface.\n\nIf for any reason you do not want to use job scripts, you can directly schedule a job using\n\nstart(Carlo.MPIScheduler, job)\n\n\n\n\n\n","category":"method"},{"location":"jobtools.html#Carlo.JobTools.TaskMaker","page":"JobTools","title":"Carlo.JobTools.TaskMaker","text":"TaskMaker()\n\nTool for generating a list of tasks, i.e. parameter sets, to be simulated in a Monte Carlo simulation.\n\nThe fields of TaskMaker can be freely assigned and each time task is called, their current state will be copied into a new task. Finally the list of tasks can be generated using make_tasks\n\nIn most cases the resulting tasks will be used in the constructor of JobInfo, the basic description for jobs in Carlo.\n\nExample\n\nThe following example creates a list of 5 tasks for different parameters T. This could be a scan of the finite-temperature phase diagram of some model. The first task will be run with more sweeps than the rest.\n\ntm = TaskMaker()\ntm.sweeps = 10000\ntm.thermalization = 2000\ntm.binsize = 500\n\ntask(tm; T=0.04)\ntm.sweeps = 5000\nfor T in range(0.1, 10, length=5)\n    task(tm; T=T)\nend\n\ntasks = make_tasks(tm)\n\n\n\n\n\n","category":"type"},{"location":"jobtools.html#Carlo.JobTools.task","page":"JobTools","title":"Carlo.JobTools.task","text":"task(tm::TaskMaker; kwargs...)\n\nCreates a new task for the current set of parameters saved in tm. Optionally, kwargs can be used to specify parameters that are set for this task only.\n\n\n\n\n\n","category":"function"},{"location":"jobtools.html#Carlo.JobTools.make_tasks","page":"JobTools","title":"Carlo.JobTools.make_tasks","text":"make_tasks(tm::TaskMaker)::Vector{TaskInfo}\n\nGenerate a list of tasks from tm based on the previous calls of task. The output of this will typically be supplied to the tasks argument of JobInfo.\n\n\n\n\n\n","category":"function"},{"location":"jobtools.html#Carlo.JobTools.current_task_name","page":"JobTools","title":"Carlo.JobTools.current_task_name","text":"current_task_name(tm::TaskMaker)\n\nReturns the name of the task that will be created by task(tm).\n\n\n\n\n\n","category":"function"},{"location":"abstract_mc.html#abstract_mc","page":"Implementing your algorithm","title":"Implementing your algorithm","text":"To run your own Monte Carlo algorithm with Carlo, you need to implement the AbstractMC interface documented in this file. For an example implementation showcasing all the features, take a look at the Ising example implementation.\n\nThe following methods all need to be defined for your Monte Carlo algoritm type (here referred to as YourMC <: AbstractMC). See Parallel run mode for a slightly different interface that allows inner MPI parallelization of your algorithm.","category":"section"},{"location":"abstract_mc.html#mc_context","page":"Implementing your algorithm","title":"Interfacing with Carlo features","text":"The MCContext type, passed to your code by some of the functions above enables to use some features provided by Carlo.","category":"section"},{"location":"abstract_mc.html#Carlo.AbstractMC","page":"Implementing your algorithm","title":"Carlo.AbstractMC","text":"This type is an interface for implementing your own Monte Carlo algorithm that will be run by Carlo.\n\n\n\n\n\n","category":"type"},{"location":"abstract_mc.html#Carlo.init!","page":"Implementing your algorithm","title":"Carlo.init!","text":"Carlo.init!(mc::YourMC, ctx::MCContext, params::AbstractDict)\n\nExecuted when a simulation is started from scratch.\n\n\n\n\n\n","category":"function"},{"location":"abstract_mc.html#Carlo.sweep!","page":"Implementing your algorithm","title":"Carlo.sweep!","text":"Carlo.sweep!(mc::YourMC, ctx::MCContext)\n\nPerform one Monte Carlo sweep or update to the configuration.\n\nnote: Note\nDoing measurements is supported during this step as some algorithms require doing so for efficiency. Remember to check for is_thermalized in that case.\n\n\n\n\n\n","category":"function"},{"location":"abstract_mc.html#Carlo.measure!","page":"Implementing your algorithm","title":"Carlo.measure!","text":"Carlo.measure!(mc::YourMC, ctx::MCContext)\n\nPerform one Monte Carlo measurement.\n\n\n\n\n\n","category":"function"},{"location":"abstract_mc.html#Carlo.write_checkpoint","page":"Implementing your algorithm","title":"Carlo.write_checkpoint","text":"Carlo.write_checkpoint(mc::YourMC, out::HDF5.Group)\n\nSave the complete state of the simulation to out.\n\n\n\n\n\n","category":"function"},{"location":"abstract_mc.html#Carlo.read_checkpoint!","page":"Implementing your algorithm","title":"Carlo.read_checkpoint!","text":"Carlo.read_checkpoint!(mc::YourMC, in::HDF5.Group)\n\nRead the state of the simulation from in.\n\n\n\n\n\n","category":"function"},{"location":"abstract_mc.html#Carlo.register_evaluables","page":"Implementing your algorithm","title":"Carlo.register_evaluables","text":"Carlo.register_evaluables(mc::Type{YourMC}, eval::AbstractEvaluator, params::AbstractDict)\n\nThis function is used to calculate postprocessed quantities from quantities that were measured during the simulation. Common examples are variances or ratios of observables.\n\nSee evaluables for more details.\n\n\n\n\n\n","category":"function"},{"location":"abstract_mc.html#Carlo.MCContext","page":"Implementing your algorithm","title":"Carlo.MCContext","text":"Holds the Carlo-internal state of the simulation and provides an interface to\n\nRandom numbers: the public field MCContext.rng is a random number generator (see rng)\nMeasurements: see measure!(::MCContext, ::Symbol, ::Any)\nSimulation state: see is_thermalized\n\n\n\n\n\n","category":"type"},{"location":"abstract_mc.html#Carlo.is_thermalized","page":"Implementing your algorithm","title":"Carlo.is_thermalized","text":"is_thermalized(ctx::MCContext) -> Bool\n\nReturns true if the simulation is thermalized.\n\n\n\n\n\n","category":"function"},{"location":"abstract_mc.html#Carlo.measure!-Tuple{MCContext, Symbol, Any}","page":"Implementing your algorithm","title":"Carlo.measure!","text":"measure!(ctx::MCContext, name::Symbol, value)\n\nMeasure a sample for the observable named name. The sample value may be either a scalar or vector of a float type. \n\n\n\n\n\n","category":"method"},{"location":"abstract_mc.html#Carlo.register_observable!","page":"Implementing your algorithm","title":"Carlo.register_observable!","text":"register_observable!(\n    ctx::MCContext,\n    obsname::Symbol;\n    binsize::Integer,\n    shape::Tuple{Vararg{Integer}} = (),\n    T = Float64\n)\n\nAllows pre-registering an observable named obsname with custom binsize, fixed dimensions shape and type T. Usually this is unnecessary: Carlo will simply do it for you when you measure! the first sample.\n\nManual registration allows you, however, to override the internal binsize of the observable, which would otherwise be set by the tm.binsize task parameter. This is useful, for example, when you want to form the histogram of a specific observable, or when you measure a specific observable less frequently than others.\n\n\n\n\n\n","category":"function"},{"location":"parallel_tempering.html#parallel_tempering","page":"Parallel tempering","title":"Parallel tempering","text":"Parallel tempering is a method to improve the statistics and ergodicity of a Markov-chain Monte Carlo simulation by running multiple copies with different parameters in parallel and allowing updates that exchange Monte Carlo configurations between the different parameters. A classical example would be to simulate a glassy model at different temperatures so that decorrelated high-temperature configurations continuously enter the low-temperature region and sample the glassy configuration space efficiently.\n\nCarlo.jl provides an implementation of parallel tempering through a “meta” implementation of the AbstractMC interface, ParallelTemperingMC. It is a Monte Carlo algorithm that can run any other AbstractMC implementation with parallel tempering.\n\nIn order to work with parallel tempering, the child algorithm only has to implement the following two methods.\n\nThe algorithm works by orchestrating a number of Monte Carlo processes along a chain of parameter values. Alternatingly, all adjacent even and odd pairs compare their configuration weights and propose a switch of their configurations. If the switch is accepted, the Monte Carlo processes exchange their positions on the chain.","category":"section"},{"location":"parallel_tempering.html#Configuration","page":"Parallel tempering","title":"Configuration","text":"When running a simulation, ParallelTemperingMC is configured through the parallel_tempering task parameter\n\nusing Carlo\nusing Carlo.JobTools\nstruct YourMC <: AbstractMC end # hide\n\nnum_steps = 10\n\ntm = TaskMaker()\n\ntm.parallel_tempering = (\n    mc = YourMC,\n    parameter = :T,\n    values = range(1, 2, num_steps),\n    interval = 20,\n)\n\ntm.sweeps = 10000\ntm.thermalization = 1000\ntm.binsize = 100\n# [set other parameters here]\n\ntask(tm)\n\njob = JobInfo(\n    \"my_job\",\n    ParallelTemperingMC;\n    checkpoint_time = \"45:00\",\n    run_time = \"24:00:00\",\n    tasks = make_tasks(tm),\n    ranks_per_run = num_steps,\n)\n\nHere, mc is the type of the child Monte Carlo algorithm that should be run with parallel tempering. parameter is the name of the parameter that should be exchanged in the parallel tempering and values is a chain of values along which exchanges take place. Care should be taken that the probability distributions for adjacent values have some overlap. interval sets the number of Monte Carlo sweeps between a tempering update. A single task set up like that will simulate the entire chain of parameter values at once. It is also possible to simulate multiple independent chains by creating multiple tasks.\n\nIn JobInfo your Monte Carlo type is then replaced by ParallelTemperingMC. Under the hood, ParallelTemperingMC runs in parallel run mode and ranks_per_run has to be set to the number of parameters in the tempering chain. The simulation then has to be run with MPI and the appropriate number of ranks, n * ranks_per_run + 1.\n\nnote: Note\nAt the moment, the child Monte Carlo algorithm can only run in single run mode. However, lifting this limitation should not be too hard. If you intend to run parallel tempering on a parallel run mode code, open an issue on GitHub.","category":"section"},{"location":"parallel_tempering.html#Results","page":"Parallel tempering","title":"Results","text":"Each observable and evaluable that is calculated by the child code is stacked into a vector where each entry corresponds to a parameter value in the parallel tempering chain. For example, if the child code in the above example calculates the energy, the output for it will be a vector with num_steps values corresponding to the different temperatures in tm.parallel_tempering.values. Observables which are already vectors or higher order arrays in the child code will gain a new last dimension which corresponds to the parallel tempering parameter.\n\nAdditionally, the observable ParallelTemperingPermutation records the permutation of configurations on the parallel tempering chain. This can be used to gauge the ergodicity of the parallel tempering updates.\n\nAnother self-contained example of parallel tempering is contained in the Ising reference implementation.","category":"section"},{"location":"parallel_tempering.html#Carlo.ParallelTemperingMC","page":"Parallel tempering","title":"Carlo.ParallelTemperingMC","text":"ParallelTemperingMC <: AbstractMC\n\nAn implementation of the parallel run mode AbstractMC interface that runs other AbstractMC implementations with parallel tempering.\n\nThe child implementation is expected to implement\n\nparallel_tempering_log_weight_ratio\nparallel_tempering_change_parameter!\n\n\n\n\n\n","category":"type"},{"location":"parallel_tempering.html#Carlo.parallel_tempering_log_weight_ratio","page":"Parallel tempering","title":"Carlo.parallel_tempering_log_weight_ratio","text":"Carlo.parallel_tempering_log_weight_ratio(mc::YourMC, parameter_name::Symbol, new_value)\n\nLet W(x p) be the the weight of the Monte Carlo configuration x at the current value of the parameter p (specified by parameter_name), and W(xp) be the weight after the parameter has been changed to new_value.\n\nThis function then returns log W(xp)W(xp).\n\n\n\n\n\n","category":"function"},{"location":"parallel_tempering.html#Carlo.parallel_tempering_change_parameter!","page":"Parallel tempering","title":"Carlo.parallel_tempering_change_parameter!","text":"Carlo.parallel_tempering_change_parameter!(mc::YourMC, parameter_name::Symbol, new_value)\n\nDuring a parallel tempering simulation, changes the parameter named parameter_name to new_value and performs all necessary updates to the internal structure of YourMC.\n\n\n\n\n\n","category":"function"},{"location":"covariance.html#covariance","page":"Covariance estimation","title":"Covariance estimation","text":"Carlo can estimate covariance matrices of observables. By default, this feature is disabled, but for tasks with the parameter tm.estimate_covariance = true, each array-valued observable and evaluable will get an additional covariance field in the .results.json file.\n\nFor scalar observables, this covariance field is always nothing. Covariances between different scalar (or array) observables can nevertheless be estimated by creating an array evaluable containing different observables as elements.","category":"section"},{"location":"covariance.html#Example-for-the-Ising-model","page":"Covariance estimation","title":"Example for the Ising model","text":"As an example where correlations become important, consider this job for the Ising reference implementation, which describes a model close to the critical point.\n\n#!/usr/bin/env julia\n\nusing Carlo\nusing Carlo.JobTools\nusing Ising\n\ntm = TaskMaker()\ntm.sweeps = 10000\ntm.thermalization = 2000\ntm.binsize = 5\n\ntm.Lx = 20\ntm.Ly = 20\n\ntm.estimate_covariance = true # enable covariance!\n\ntm.T = 2.27\ntask(tm)\n\njob = JobInfo(splitext(@__FILE__)[1], Ising.MC;\n    checkpoint_time=\"30:00\",\n    run_time=\"15:00\",\n    tasks=make_tasks(tm)\n)\n\nstart(dummy, dummy2) = nothing # hide\nstart(job, ARGS)\n\nAfter running this job with ./covariance_job.jl run, we extract the results using Carlo.ResultTools.\n\nusing Plots\nusing DataFrames\nusing Carlo.ResultTools\n\ndf = DataFrame(ResultTools.dataframe(\"covariance_job.results.json\"))\n\nplot(df.SpinCorrelation[1]; xlabel = \"x\", ylabel = \"Spin correlation C(x)\")\n\nBecause we are close to the critical point, the correlation function decays slowly. When interpreting this data, e.g. using a fit, it is important to remember that the statistical fluctuations of the different values are not independent. They too, are highly correlated.\n\nFor each observable or evaluable that has a covariance matrix estimate, ResultTools.dataframe will create a new column of the form *_cov, containing the covariance matrix. If the observable itself is a matrix or a rank-n tensor, the covariance matrix will be a rank-2n tensor.\n\nheatmap(df.SpinCorrelation_cov[1]; xlabel = \"C(x)\", ylabel=\"C(x')\", c = :Blues, rightmargin=5Plots.mm)\n\nAs we see, the statistical averages of the different components of the spin-spin correlation function are completely correlated. We can use the covariance matrix to account for this in further postprocessing.\n\nAnother application of the covariance matrix is the control variates method.","category":"section"},{"location":"covariance.html#Alternative-approaches","page":"Covariance estimation","title":"Alternative approaches","text":"Alternatively to measuring the covariance matrix, users may also choose to perform their own bootstrapping on the raw measurement data in the .meas.h5 files.","category":"section"},{"location":"covariance.html#Autocorrelation-time","page":"Covariance estimation","title":"Autocorrelation time","text":"When observables are strongly correlated, hidden autocorrelations can appear that are scrambled between different components. The resulting autocorrelation time may be underestimated by the standard estimator based on the rebinned error. When covariance estimation is enabled, Carlo will automatically use the covariance matrix to improve the estimate of the autocorrelation time by rotating to its eigenbasis:\n\nτ = frac12 max_i leftΛ^-frac12 U^dagger Σ_overlineX U Λ^-frac12 - 1right_ii\n\nwhere Σ_overlineX is the covariance matrix of the mean of observable X (obtained from rebinning) and Σ_X = U Λ U^dagger is the eigendecomposition of the covariance matrix of X without rebinning.\n\nJust like without covariance estimation, this autocorrelation time is in units of the internal binsize. Furthermore, this estimator may still be inaccurate in cases where Σ_overlineX and Σ_X have very different eigenbases.","category":"section"},{"location":"resulttools.html#result_tools","page":"ResultTools","title":"ResultTools","text":"This is a small module to ease importing Carlo results back into Julia. It contains the function\n\nIf we use ResultTools with DataFrames.jl to read out the results of the Ising example, it would be the following.\n\nusing Plots\nusing DataFrames\nusing Carlo.ResultTools\n\ndf = DataFrame(ResultTools.dataframe(\"example.results.json\"))\n\nplot(df.T, df.Energy; xlabel = \"Temperature\", ylabel=\"Energy per spin\", group=df.Lx, legendtitle=\"L\")\n\nIn the plot we can nicely see how the model approaches the ground state energy at low temperatures.","category":"section"},{"location":"resulttools.html#Carlo.ResultTools.dataframe","page":"ResultTools","title":"Carlo.ResultTools.dataframe","text":"ResultTools.dataframe(result_json::AbstractString)\n\nHelper to import result data from a *.results.json file produced after a Carlo calculation. Returns a Tables.jl-compatible dictionary that can be used as is or converted into a DataFrame or other table structure. Observables and their errorbars will be converted to Measurements.jl measurements.\n\n\n\n\n\n","category":"function"},{"location":"index.html#Carlo.jl","page":"Carlo.jl","title":"Carlo.jl","text":"","category":"section"},{"location":"index.html#Overview","page":"Carlo.jl","title":"Overview","text":"Carlo is a framework that aims to simplify the implementation of high-performance Monte Carlo codes by handling the parallelization, checkpointing and error analysis. What sets it apart is a focus on ease of use and minimalism.","category":"section"},{"location":"index.html#Installation","page":"Carlo.jl","title":"Installation","text":"Installation is simple via the Julia REPL.\n\n] add Carlo\n\nIf you wish to use the system MPI implementation, take a look at the MPI.jl documentation and be aware that in that case also the system binary of HDF5 as described here!","category":"section"},{"location":"index.html#Usage","page":"Carlo.jl","title":"Usage","text":"In order to work with Carlo, a Monte Carlo algorithm has to implement the AbstractMC interface. A full example of this is given in the reference implementation for the Ising model.\n\nThen, to perform simulation, one writes a job script defining all the parameters needed for the simulation, which could look something like the following.\n\n#!/usr/bin/env julia\n\nusing Carlo\nusing Carlo.JobTools\nusing Ising\n\ntm = TaskMaker()\ntm.sweeps = 10000\ntm.thermalization = 2000\ntm.binsize = 100\n\ntm.Lx = 10\ntm.Ly = 10\n\nTs = range(0.1, 4, length=20)\nfor T in Ts\n    task(tm; T=T)\nend\n\njob = JobInfo(@__FILE__, Ising.MC;\n    checkpoint_time=\"30:00\",\n    run_time=\"15:00\",\n    tasks=make_tasks(tm)\n)\n\nstart(dummy, dummy2) = nothing # hide\nstart(job, ARGS)\n\nThis example starts a simulation for the Ising model on the 10×10 lattice for 20 different temperatures. Using the function start(job::JobInfo, ARGS) enables the Carlo CLI when we  execute the script above as follows.\n\n./myjob --help\n\nThe command line interface allows (re)starting a job, merging preliminary results, and showing the completion status of a calculation.","category":"section"},{"location":"index.html#Starting-jobs","page":"Carlo.jl","title":"Starting jobs","text":"./myjob run\n\nThis will start a simulation on a single core. To use multiple cores, use MPI.\n\nmpirun -n $num_cores ./myjob run\n\nOnce the simulation is started, a directory myjob.data will be created to store all simulation data. The name of the directory corresponds to the first argument of JobInfo. Usually that will be @__FILE__, but you could also collect your simulation data in a different directory.\n\nThe data directory will contain hdf5 files for each task of the job that contain checkpointing snapshots and measurement results. Once the job is done, Carlo will average the measurement data for you and produce the file myjob.results.json in the same directory as the myjob.data directory. This file contains means and errorbars of all observables. See ResultTools for some tips on consuming this file back into julia for your plotting or other postprocessing.","category":"section"},{"location":"index.html#Job-status","page":"Carlo.jl","title":"Job status","text":"./myjob status\n\nUse this command to find out the state of the simulation. It will show a table with the number of completed measurement sweeps, the target number of sweeps, the numbers of runs, and the fraction of them that is thermalized.\n\nThe fraction is defined as thermalization sweeps completed/total thermalization sweeps needed.","category":"section"},{"location":"index.html#Merging-jobs","page":"Carlo.jl","title":"Merging jobs","text":"./myjob merge\n\nUsually Carlo will automatically merge results once a job is complete, but when you are impatient and you want to check on results of a running or aborted job, this command is your friend. It will produce a myjob.results.json file containing the averages of the currently available data.","category":"section"},{"location":"index.html#Deleting-jobs","page":"Carlo.jl","title":"Deleting jobs","text":"./myjob delete\n\nThis deletes myjob.data and myjob.results.json. Of course, you should archive your simulation data instead of deleting them. However, if you made an error in a previous simulation, keep in mind that by default Carlo will continue it from the checkpoints.\n\nFor that case of restarting a job there is a handy shortcut as well\n\n./myjob run --restart","category":"section"},{"location":"index.html#Shortcuts","page":"Carlo.jl","title":"Shortcuts","text":"All commands here have shortcut versions that you can view in the help.","category":"section"},{"location":"rng.html#rng","page":"Random Number Generators","title":"Random Number Generators","text":"Carlo takes care of storing and managing the state of random number generators (RNG) for you. It is accessible through the rng field of MCContext and the type of RNG to use can be set by the rng parameter in every task (see TaskInfo).\n\nThe currently supported types are\n\nRandom.Xoshiro","category":"section"}]
}
